{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3e57cbb-39ba-480d-a06b-16ac9b2c0f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import tarfile\n",
    "\n",
    "def fetch_spam_data():\n",
    "    spam_root = \"https://spamassassin.apache.org/old/publiccorpus/\"\n",
    "    fileinfos = [\n",
    "        (\"easy_ham_2\", \"20030228_easy_ham_2.tar.bz2\"),\n",
    "        (\"hard_ham\", \"20030228_hard_ham.tar.bz2\"),\n",
    "        (\"spam_2\", \"20050311_spam_2.tar.bz2\"),\n",
    "    ]\n",
    "\n",
    "    spam_path = Path() / \"datasets\" / \"spam\"\n",
    "    spam_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for folder_name, tar_filename in fileinfos:\n",
    "        if not (spam_path / folder_name).is_dir():\n",
    "            url = spam_root + tar_filename\n",
    "            path = spam_path / tar_filename\n",
    "            print(\"Downloading\", path.name)\n",
    "            urllib.request.urlretrieve(url, path)\n",
    "            with tarfile.open(path) as tar:\n",
    "                tar.extractall(path=spam_path)\n",
    "\n",
    "    return [spam_path / folder_name for folder_name, _ in fileinfos]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c97d9f4-35fc-4d77-afa8-65250d5104d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "easy_ham_dir, hard_ham_dir, spam_dir = fetch_spam_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c127ac1-128a-47b4-8c71-3895c07bd98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "easy_ham_filenames = [f for f in sorted(easy_ham_dir.iterdir()) if len(f.name) > 20]\n",
    "hard_ham_filenames = [f for f in sorted(hard_ham_dir.iterdir()) if len(f.name) > 20]\n",
    "spam_filenames = [f for f in sorted(spam_dir.iterdir()) if len(f.name) > 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d98040d-64a0-497b-ab46-ffc8de59fef1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1400"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(easy_ham_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "205192cd-9f7a-4354-a6d4-a84d7d77a0a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "250"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hard_ham_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "761e0c7e-6fc3-4ec2-9c8f-a9389aebc209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1396"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spam_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7540515-dbfe-428f-9f99-718e8521dad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import email\n",
    "import email.policy\n",
    "\n",
    "def load_email(filepath):\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        return email.parser.BytesParser(policy=email.policy.default).parse(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "107e3366-7e8c-4601-bc4e-129b270e4090",
   "metadata": {},
   "outputs": [],
   "source": [
    "easy_ham_emails = [load_email(filepath) for filepath in easy_ham_filenames]\n",
    "hard_ham_emails = [load_email(filepath) for filepath in hard_ham_filenames]\n",
    "spam_emails = [load_email(filepath) for filepath in spam_filenames]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "104a8fec-cc49-4463-9ad7-f2c6e1e1fa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_emails = easy_ham_emails + hard_ham_emails\n",
    "# combines the easy_ham list and the hard_ham. I'm trying to avoid underfitting of hard_ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80172508-8009-44e1-a7bd-f8b456e063a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi!\n",
      "\n",
      "Is there a command to insert the signature using a combination of keys and not \n",
      "to have sent the mail to insert it then?\n",
      "\n",
      "Regards,\n",
      "Ulises\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "_______________________________________________\n",
      "Exmh-users mailing list\n",
      "Exmh-users@redhat.com\n",
      "https://listman.redhat.com/mailman/listinfo/exmh-users\n"
     ]
    }
   ],
   "source": [
    "print(ham_emails[10].get_content().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22572789-02a8-4bc9-853d-ba81ec4d0a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# shuffles the list in place\n",
    "random.shuffle(ham_emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f66031c7-428d-4f12-a543-404d283bde50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I think there's a link to all the details on welcomehome.org, but \n",
      "basically it was told to me this way: govt wanted land in arizona or someplace, \n",
      "indians said no, govt said 'okay, u know that land in MS u want?  we will \n",
      "fux0r it, then.'  indians still said no, govt fux0red it.\n",
      "C\n",
      "\n",
      "On Wed, 31 Jul 2002, Elias Sinderson wrote:\n",
      "\n",
      "> Heh. Never mind the perfectly good desert in the southwest, right? Or is \n",
      "> that area too hot for desert warfare training? I'll never understand.\n",
      "> \n",
      "> E\n",
      "> \n",
      "> CDale wrote:\n",
      "> \n",
      "> >Okay, I'll ammend that to LIVE OLD tree saving, like the thousands of \n",
      "> >acres of virgin pine forest that was razed here in MS so that our military \n",
      "> >can practice desert warfare?  Fought it for years, lost, now there is a \n",
      "> >stand of trees up and down Hwy 49 that's supposed to try to hide the fact \n",
      "> >that a huge portion of the Desoto Ntl. Forest is gone.\n",
      "> >\n",
      "> \n",
      "> \n",
      "> http://xent.com/mailman/listinfo/fork\n",
      "> \n",
      "\n",
      "-- \n",
      "\"My theology, briefly, is that the universe was dictated but not\n",
      "          signed.\"  (Christopher Morley) \n",
      "\n",
      "\n",
      "http://xent.com/mailman/listinfo/fork\n"
     ]
    }
   ],
   "source": [
    "print(ham_emails[10].get_content().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25061ed1-5473-4340-a6a4-fab2de0c262d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halloechen!\n",
      "\n",
      "If I create an RPM according to one of the how-to's with having\n",
      "Red Hat in mind, how big are my chances that it will also work\n",
      "for the SuSE distribution, or others?  (I don't know how many\n",
      "base on the RPM system.)\n",
      "\n",
      "Or what must I pay attention to when creating an RPM that should\n",
      "work with the big distributions?\n",
      "\n",
      "Tschoe,\n",
      "Torsten.\n",
      "\n",
      "_______________________________________________\n",
      "RPM-List mailing list <RPM-List@freshrpms.net>\n",
      "http://lists.freshrpms.net/mailman/listinfo/rpm-list\n"
     ]
    }
   ],
   "source": [
    "print(ham_emails[1].get_content().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f89189e7-0cc0-43b5-95a8-1a8c2d2f4912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW PRODUCT ANNOUNCEMENT\n",
      "\n",
      "From: OUTSOURCE ENG.& MFG. INC.\n",
      "\n",
      "\n",
      "Sir/Madam;\n",
      "\n",
      "This note is to inform you of new watchdog board technology for maintaining\n",
      "continuous unattended operation of PC/Servers etc. that we have released for\n",
      "distribution.\n",
      "  \n",
      "We are proud to announce Watchdog Control Center featuring MAM (Multiple\n",
      "Applications Monitor) capability.\n",
      "The key feature of this application enables you to monitor as many\n",
      "applications as you\n",
      "have resident on any computer as well as the operating system for\n",
      "continuous unattended operation.  The Watchdog Control Center featuring\n",
      "MAM capability expands third party application \"control\" of a Watchdog as\n",
      "access to the application's\n",
      "source code is no longer needed.\n",
      "\n",
      "Here is how it all works:\n",
      "Upon installation of the application and Watchdog, the user may select\n",
      "many configuration options, based on their model of Watchdog, to fit their\n",
      "operational needs.  If the MAM feature is enabled, the user may select any\n",
      "executable program that they wish for monitoring.\n",
      "\n",
      "A lock up of the operating system or if any one of the selected\n",
      "applications is not running, the MAM feature, in\n",
      "conjunction with the Watchdog, will reset the system allowing for\n",
      "continuous operation.\n",
      "\n",
      "It's that simple!\n",
      "\n",
      "Watchdog Control Center is supported on most Microsoft Windows platforms\n",
      "(Win9x/WinNT/Win2k) and includes a Linux version for PCI Programmable\n",
      "Watchdogs.\n",
      "\n",
      "Watchdog Control Center Features:\n",
      "- Automated installation\n",
      "- Controls all Outsource Engineering Watchdogs\n",
      "- User selectable Watchdog timeout period\n",
      "- User selectable Watchdog stroke interval\n",
      "- Multiple Application Monitoring\n",
      "\n",
      "Included on the Installation CD:\n",
      "- Watchdog Control Center\n",
      "- Watchdog Drivers\n",
      "- Documentation\n",
      "\n",
      "For more information, please visit out website at\n",
      "http://www.outsrc-em.com/ or send an e-mail to sales@outsrc-em.com\n"
     ]
    }
   ],
   "source": [
    "print(spam_emails[6].get_content().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2d9307d-f519-4c84-b518-99c061d6bdff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes we do purchase uncollected Judicial Judgements!!!            st10                           .           \n",
      "\n",
      "If you, your company or an acquaintance have an uncollected Judicial Judgement then please call us and find out how we can help you receive the money that the court states you are rightfully due.\n",
      "\n",
      "We have strong interest in acquiring uncollected Judicial Judgements in your City and Area.\n",
      "\n",
      "J T C is the largest firm in the world specializing in the purchase and collection of Judicial Judgements.\n",
      "\n",
      "Currently we are processing over 455 million dollars worth of judgements in the United States alone. We have associate offices in virtually every city in the US and in most foreign countries.\n",
      "\n",
      "You have nothing to lose and everything to gain by calling. There is absolutely no cost to you.\n",
      "\n",
      "We can be reached Toll free at 1-888-557-5744. in the US or if you are in Canada call 1-310-842-3521. You can call 24 hours per day.\n",
      "\n",
      "Thank you for your time.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "This ad is produced and sent out by: Add Systems,  NY, NY 1 1 2 2 2. To be  r e m o v e d from our mailing list please email us at boogins@hiphopmaster.com  with r e m o v e in the subject.\n",
      "++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
      "\n",
      "\n",
      "***********************************\n",
      "9385\n"
     ]
    }
   ],
   "source": [
    "print(spam_emails[10].get_content().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "68615d60-a5a7-4a4b-bf61-8cb29f7597f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_email_structure(email):\n",
    "    if isinstance(email, str):\n",
    "        return email\n",
    "    payload = email.get_payload()\n",
    "    if isinstance(payload, list):\n",
    "        multipart = \", \".join([get_email_structure(sub_email)\n",
    "                              for sub_email in payload])\n",
    "        return f\"multipart({multipart})\"\n",
    "    else:\n",
    "        return email.get_content_type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9aa6e1b4-8737-4d95-972d-282947b1d73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def structures_counter(emails):\n",
    "    structures = Counter()\n",
    "    for email in emails:\n",
    "        structure = get_email_structure(email)\n",
    "        structures[structure] += 1\n",
    "    return structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0058efb0-6bff-4b50-8dd4-76ac69c7c93d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1650"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ham_emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "85c1c88c-9666-4eba-a3b8-681e502ed3ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1396"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(spam_emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d684a39e-7abb-43cd-91e2-87580f6ca693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('text/plain', 1424),\n",
       " ('text/html', 120),\n",
       " ('multipart(text/plain, text/html)', 55),\n",
       " ('multipart(text/plain, application/pgp-signature)', 35),\n",
       " ('multipart(text/html)', 2),\n",
       " ('multipart(text/plain, image/bmp)', 1),\n",
       " ('multipart(multipart(text/plain, text/html), image/jpeg, image/gif, image/gif, image/gif, image/gif)',\n",
       "  1),\n",
       " ('multipart(multipart(text/plain, multipart(text/plain), text/plain), application/pgp-signature)',\n",
       "  1),\n",
       " ('multipart(text/plain, application/x-patch)', 1),\n",
       " ('multipart(text/plain, application/ms-tnef, text/plain)', 1),\n",
       " ('multipart(text/plain, text/plain)', 1),\n",
       " ('multipart(multipart(text/plain, text/html), image/gif, image/gif, image/gif, image/gif, image/gif, image/gif, image/gif, image/gif, image/gif, image/gif, image/gif, image/jpeg, image/gif, image/gif, image/gif, image/gif, image/gif, image/gif)',\n",
       "  1),\n",
       " ('multipart(text/plain, application/ms-tnef)', 1),\n",
       " ('multipart(text/plain, multipart(text/plain))', 1),\n",
       " ('multipart(multipart(text/plain, text/html))', 1),\n",
       " ('multipart(text/plain, multipart(text/plain, text/plain), text/rfc822-headers)',\n",
       "  1),\n",
       " ('multipart(text/plain, image/png, image/png)', 1),\n",
       " ('multipart(text/plain, text/plain, text/plain)', 1),\n",
       " ('multipart(text/plain, application/x-pkcs7-signature)', 1)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structures_counter(ham_emails).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ae773130-9e10-48f2-a7a7-1666f5325e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('text/plain', 597),\n",
       " ('text/html', 589),\n",
       " ('multipart(text/plain, text/html)', 114),\n",
       " ('multipart(text/html)', 29),\n",
       " ('multipart(text/plain)', 25),\n",
       " ('multipart(multipart(text/html))', 18),\n",
       " ('multipart(multipart(text/plain, text/html))', 5),\n",
       " ('multipart(text/plain, application/octet-stream, text/plain)', 3),\n",
       " ('multipart(text/html, text/plain)', 2),\n",
       " ('multipart(text/html, image/jpeg)', 2),\n",
       " ('multipart(multipart(text/plain), application/octet-stream)', 2),\n",
       " ('multipart(text/plain, application/octet-stream)', 2),\n",
       " ('multipart(text/plain, multipart(text/plain))', 1),\n",
       " ('multipart(multipart(text/plain, text/html), image/jpeg, image/jpeg, image/jpeg, image/jpeg, image/jpeg)',\n",
       "  1),\n",
       " ('multipart(multipart(text/plain, text/html), image/jpeg, image/jpeg, image/jpeg, image/jpeg, image/gif)',\n",
       "  1),\n",
       " ('text/plain charset=us-ascii', 1),\n",
       " ('multipart(multipart(text/html), image/gif)', 1),\n",
       " ('multipart(multipart(text/plain, text/html), application/octet-stream, application/octet-stream, application/octet-stream, application/octet-stream)',\n",
       "  1),\n",
       " ('multipart(multipart(text/plain, text/html), image/gif, image/jpeg)', 1),\n",
       " ('multipart/alternative', 1)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structures_counter(spam_emails).most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0c8afbdf-97b2-45c1-9969-954d8ddfa2f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[ILUG] STOP THE MLM INSANITY'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_emails[0][\"Subject\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5ca1feb4-01f1-45f0-b9c9-b973a693dd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.array(ham_emails + spam_emails, dtype=object)\n",
    "y = np.array([0] * len(ham_emails) + [1] * len(spam_emails))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
    "                                                   random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e580ee6d-d0f7-4f26-ae4d-94306d1dba0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from html import unescape\n",
    "\n",
    "def html_to_plain_text(html):\n",
    "    text = re.sub(r'<head.*?>.*?</head>', '', html, flags=re.M | re.S | re.I)\n",
    "    text = re.sub(r'<a\\s.*?>', ' HYPERLINK ', text, flags=re.M | re.S | re.I)\n",
    "    text = re.sub(r'<.*?>', '', text, flags=re.M | re.S)\n",
    "    text = re.sub(r'(\\s*\\n)+', '\\n', text, flags=re.M | re.S)\n",
    "    return unescape(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "255c637d-a388-4a95-bb29-0fcbb5ef4888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "<head>\n",
      "<title>Web Letter</title>\n",
      "<LINK REL=\"stylesheet\" HREF=\"http://www.sancristobalsa.net/letter/styles.css\" TYPE=\"text/css\"> \n",
      "<style>\n",
      "<!--\n",
      "body\n",
      "{\n",
      "background-image:\n",
      "url(http://www.sancristobalsa.net/letter/images/bg.gif);\n",
      "background-repeat: repeat-y;\n",
      "background-position: top left\n",
      "}\n",
      "//-->\n",
      "</style>\n",
      "</head>\n",
      "<body bgcolor=\"#FFFFFF\" marginwidth=\"0\" marginheight=\"0\" topmargin=\"0\" leftmargin=\"0\">\n",
      "<table align=\"left\" cellpadding=\"0\" cellspacing=\"0\" border=\"0\" width=\"760\">\n",
      " <tr>\n",
      "  <td colspan=\"2\"><img src=\"http://www.sancristobalsa.net/letter/images/header.jpg\" width=\"760\" height=\"90\" border=\"0\" alt=\"\"></td>\n",
      " </tr>\n",
      " <tr>\n",
      "  <td align=\"left\" width=\"190\" valign=\"top\"><br>\n",
      "<table align=\"left\" cellpadding=\"0\" cellspacing=\"0\" border=\"0\" width=\"190\">\n",
      " <tr><td><img src=\"http://www.sancristobalsa.net/letter/images/set1.jpg\" width=\"190\" height=\"400\" border=\"0\" alt=\"\"></td></tr>\n",
      " <tr><td><img src=\"http://www.sancristobalsa.net/letter/images/set2.jpg\" width=\"190\" height=\"360\" border=\"0\" alt=\"\"></t ...\n"
     ]
    }
   ],
   "source": [
    "html_spam_emails = [email for email in X_train[y_train==1]\n",
    "                   if get_email_structure(email) == \"text/html\"]\n",
    "sample_html_spam = html_spam_emails[7]\n",
    "print(sample_html_spam.get_content().strip()[:1000], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "99ddb419-beea-4a96-9115-4f46592512e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                Tremendous Investment Opportunity!\n",
      "                Are you are fed up with the manipulation and erratic performance of the stock market?  Like most people, are you looking for a stable investment that can provide a 25%-35% tax-free annual cash flow return?  If you answered yes to either question, I have an exciting offering for you.\n",
      "     I represent a company that has a limited offering of emerging growth Caribbean Real Estate that enjoins a tropical working farm, which provides substantial cash flow, long-term wealth accumulation, and the proven appreciation of Caribbean real estate.\n",
      "                Here are the details:\n",
      "                                             A 20-acre tract of waterfront Caribbean real estate is only $106,000 (including closing costs and dual residency status in a tax-advantaged country).\n",
      "    The investment will be totally private and protected from lawsuits.\n",
      "                                                 The plantation has a proven track rec ...\n"
     ]
    }
   ],
   "source": [
    "print(html_to_plain_text(sample_html_spam.get_content())[:1000], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "532ae66a-c3f1-4335-9f22-6e79d82086ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_to_text(email):\n",
    "    html = None\n",
    "    for part in email.walk():\n",
    "        ctype = part.get_content_type()\n",
    "        if ctype not in (\"text/plain\", \"text/html\"):\n",
    "            continue\n",
    "        try:\n",
    "            payload = part.get_payload(decode=True)\n",
    "            charset = part.get_content_charset()\n",
    "            if charset is None:\n",
    "                charset = \"utf-8\"\n",
    "            content = payload.decode(charset, errors=\"replace\")\n",
    "        except Exception as e:\n",
    "            print(f\"Decoding error: {e}\")\n",
    "            content = str(part.get_payload())\n",
    "\n",
    "        if ctype == \"text/plain\":\n",
    "            return content.strip()\n",
    "        else:\n",
    "            html = content\n",
    "\n",
    "    if html:\n",
    "        return html_to_plain_text(html)\n",
    "    return \"\"\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "71f5e0ef-d6b8-4c12-83b3-b1ab78b6ab51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                Tremendous Investment Opportunity!\n",
      "                Are you are fed up with the mani ...\n"
     ]
    }
   ],
   "source": [
    "print(email_to_text(sample_html_spam)[:100], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f2437cd4-57c6-49c2-87fc-5ee2613a6b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computations => comput\n",
      "Computation => comput\n",
      "Computing => comput\n",
      "Computed => comput\n",
      "Compute => comput\n",
      "Compulsive => compuls\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "stemmer = nltk.PorterStemmer()\n",
    "for word in (\"Computations\", \"Computation\", \"Computing\", \"Computed\", \"Compute\", \n",
    "            \"Compulsive\"):\n",
    "    print(word, \"=>\", stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "74d158a1-1165-4bab-94e1-cedf2e210667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['github.com', 'https://youtu.be/7Pq-S557XQU?t=3m32s']\n"
     ]
    }
   ],
   "source": [
    "import urlextract\n",
    "\n",
    "url_extractor = urlextract.URLExtract()\n",
    "some_text = \"Will it detect github.com and https://youtu.be/7Pq-S557XQU?t=3m32s\"\n",
    "print(url_extractor.find_urls(some_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5f82f9bb-dd98-48a9-b351-fea9956871b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class EmailToWordCounterTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, strip_headers=True, lower_case=True,\n",
    "                remove_punctuation=True, replace_urls=True,\n",
    "                replace_numbers=True, stemming=True):\n",
    "        self.strip_headers = strip_headers\n",
    "        self.lower_case = lower_case\n",
    "        self.remove_punctuation = remove_punctuation\n",
    "        self.replace_urls = replace_urls\n",
    "        self.replace_numbers = replace_numbers\n",
    "        self.stemming = stemming\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = []\n",
    "        for email in X:\n",
    "            text = email_to_text(email) or \"\"\n",
    "            if self.lower_case:\n",
    "                text = text.lower()\n",
    "            if self.replace_urls and url_extractor is not None:\n",
    "                urls = list(set(url_extractor.find_urls(text)))\n",
    "                urls.sort(key=lambda url: len(url), reverse=True)\n",
    "                for url in urls:\n",
    "                    text = text.replace(url, \" URL \")\n",
    "            if self.replace_numbers:\n",
    "                text = re.sub(r'\\d+(?:\\.\\d*)?(?:[eE][+-]?\\d+)?', 'NUMBER', text)\n",
    "            if self.remove_punctuation:\n",
    "                text = re.sub(r'\\W+', ' ', text, flags=re.M)\n",
    "            word_counts = Counter(text.split())\n",
    "            if self.stemming and stemmer is not None:\n",
    "                stemmed_word_counts = Counter()\n",
    "                for word, count in word_counts.items():\n",
    "                    stemmed_word = stemmer.stem(word)\n",
    "                    stemmed_word_counts[stemmed_word] += count\n",
    "                word_counts = stemmed_word_counts\n",
    "            X_transformed.append(word_counts)\n",
    "        return np.array(X_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "756e6a26-34ff-4a71-89ff-7def10a94c6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([Counter({'i': 14, 'the': 9, 'to': 6, 'firewal': 5, 'a': 5, 'linux': 5, 'so': 4, 'connect': 4, 'have': 4, 'at': 3, 'my': 3, 'usb': 3, 'and': 3, 'be': 3, 'of': 3, 'adsl': 3, 'what': 3, 'm': 2, 'configur': 2, 'thi': 2, 'that': 2, 'box': 2, 'one': 2, 've': 2, 'as': 2, 'do': 2, 'nat': 2, 'am': 2, 'need': 2, 'router': 2, 'option': 2, 'look': 2, 'are': 2, 'modem': 2, 'machin': 2, 'would': 2, 'ie': 2, 'moment': 1, 'still': 1, 'found': 1, 'out': 1, 'ha': 1, 'dodgi': 1, 'await': 1, 'pci': 1, 'control': 1, 'finish': 1, 'meant': 1, 'buy': 1, 'yesterday': 1, 'forgot': 1, 'bought': 1, 'smoothwal': 1, 'corpor': 1, 'edit': 1, 'it': 1, 'best': 1, 'rout': 1, 'solut': 1, 'around': 1, 'or': 1, 'been': 1, 'led': 1, 'believ': 1, 'will': 1, 'proxi': 1, 'mayb': 1, 'vpn': 1, 'too': 1, 'but': 1, 'we': 1, 'shall': 1, 'see': 1, 'cw': 1, 'hi': 1, 'all': 1, 'serious': 1, 'think': 1, 'get': 1, 'solo': 1, 'from': 1, 'eircom': 1, 'also': 1, 'more': 1, 'than': 1, 'comput': 1, 'therefor': 1, 'can': 1, 'them': 1, 'togeth': 1, 'number': 1, 'with': 1, 'act': 1, 'combin': 1, 'which': 1, 'directli': 1, 'question': 1, 'recommend': 1, 'ani': 1, 'you': 1, 'about': 1, 'abov': 1, 'onli': 1, 'vagu': 1, 'idea': 1, 'doe': 1, 'other': 1, 'should': 1, 'thank': 1, 'con': 1, 'irish': 1, 'user': 1, 'group': 1, 'ilug': 1, 'url': 1, 'for': 1, 'un': 1, 'subscript': 1, 'inform': 1, 'list': 1, 'maintain': 1, 'listmast': 1}),\n",
       "       Counter({'natur': 4, 'for': 3, 'and': 3, 'your': 3, 's': 3, 'increas': 3, 'hyperlink': 2, 'mother': 2, 'all': 2, 'men': 2, 'women': 2, 'risk': 2, 'free': 2, 'the': 2, 'formula': 2, 'marit': 1, 'aid': 1, 'safe': 1, 'number': 1, 'day': 1, 'wonder': 1, 'pill': 1, 'of': 1, 'numberst': 1, 'centuri': 1, 'sensationincreas': 1, 'frequenc': 1, 'pleasureincreas': 1, 'desir': 1, 'staminaincreas': 1, 'libido': 1, 'both': 1, 'male': 1, 'femal': 1, 'order': 1, 'trial': 1, 'today': 1, 'to': 1, 'depart': 1, 'from': 1, 'further': 1, 'contact': 1, 'visit': 1, 'here': 1, 'vidal': 1, 'url': 1}),\n",
       "       Counter({'number': 62, 'url': 2, 'around': 1, 'the': 1, 'world': 1, 'there': 1, 'is': 1, 'a': 1, 'grow': 1, 'sens': 1, 'that': 1, 'democraci': 1, 'ha': 1, 'not': 1, 'deliv': 1, 'develop': 1, 'sakiko': 1, 'fukuda': 1, 'parr': 1, 'un': 1, 'report': 1, 'author': 1, 'hdi': 1, 'rank': 1, 'lifeexp': 1, 'infantmort': 1, 'gdp': 1, 'percapita': 1, 'adultlit': 1, 'norway': 1, 'sweden': 1, 'canada': 1, 'belgium': 1, 'australia': 1, 'unit': 1, 'state': 1, 'iceland': 1, 'netherland': 1, 'japan': 1, 'finland': 1})],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_few = X_train[:3]\n",
    "X_few_wordcounts = EmailToWordCounterTransformer().fit_transform(X_few)\n",
    "X_few_wordcounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "244adbc5-8889-445b-956c-32b638afa968",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "class WordCounterToVectorTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, vocabulary_size=1000):\n",
    "        self.vocabulary_size = vocabulary_size\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        total_count = Counter()\n",
    "        for word_count in X:\n",
    "            for word, count in word_count.items():\n",
    "                total_count[word] += min(count, 10)\n",
    "        most_common = total_count.most_common()[:self.vocabulary_size]\n",
    "        self.vocabulary_ = {word: index + 1\n",
    "                           for index, (word, count) in enumerate(most_common)}\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        rows = []\n",
    "        cols = []\n",
    "        data = []\n",
    "\n",
    "        for row, word_count in enumerate(X):\n",
    "            for word, count in word_count.items():\n",
    "                rows.append(row)\n",
    "                cols.append(self.vocabulary_.get(word, 0))\n",
    "                data.append(count)\n",
    "        return csr_matrix((data, (rows, cols)),\n",
    "                         shape=(len(X), self.vocabulary_size + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "98694ee5-2cc1-45f3-90e4-ab8388f70350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
       "\twith 21 stored elements and shape (3, 11)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_transformer = WordCounterToVectorTransformer(vocabulary_size=10)\n",
    "X_few_vectors = vocab_transformer.fit_transform(X_few_wordcounts)\n",
    "X_few_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "19f71508-2ba0-4271-9d55-aeca03b95c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[150,   9,   1,  14,   6,   5,   3,   5,   5,   4,   3],\n",
       "       [ 60,   2,   1,   0,   1,   0,   3,   0,   0,   0,   1],\n",
       "       [ 38,   1,  62,   0,   0,   1,   0,   0,   0,   0,   0]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_few_vectors.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "32c2f4f8-5d5b-4109-8714-a4f353fbde89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 1,\n",
       " 'number': 2,\n",
       " 'i': 3,\n",
       " 'to': 4,\n",
       " 'a': 5,\n",
       " 'and': 6,\n",
       " 'firewal': 7,\n",
       " 'linux': 8,\n",
       " 'so': 9,\n",
       " 'of': 10}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_transformer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "509f5710-34ff-47b1-a845-a2bd4321a42e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding error: unknown encoding: default\n",
      "Decoding error: unknown encoding: default\n",
      "Decoding error: unknown encoding: default_charset\n",
      "Decoding error: unknown encoding: default_charset\n",
      "Decoding error: unknown encoding: gb2312_charset\n",
      "Decoding error: unknown encoding: default\n",
      "Decoding error: unknown encoding: chinesebig5\n",
      "Decoding error: unknown encoding: default\n",
      "Decoding error: unknown encoding: default_charset\n",
      "Decoding error: unknown encoding: default\n",
      "Decoding error: unknown encoding: default\n",
      "Decoding error: unknown encoding: default\n",
      "Decoding error: unknown encoding: default_charset\n",
      "Decoding error: unknown encoding: default\n",
      "Decoding error: unknown encoding: default_charset\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "preprocess_pipeline_vec = Pipeline([\n",
    "    (\"email_to_wordcount\", EmailToWordCounterTransformer()),\n",
    "    (\"wordcount_to_vector\", WordCounterToVectorTransformer())\n",
    "])\n",
    "X_train_transform_vec = preprocess_pipeline_vec.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5b449368-a3d3-41dc-bc27-9fe045f37dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmailToTextTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = []\n",
    "        for email_obj in X:\n",
    "            text = email_to_text(email_obj) or \"\"\n",
    "            X_transformed.append(text)\n",
    "        return np.array(X_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9449f37e-2b02-402f-be37-69a031531d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding error: unknown encoding: default\n",
      "Decoding error: unknown encoding: default\n",
      "Decoding error: unknown encoding: default_charset\n",
      "Decoding error: unknown encoding: default_charset\n",
      "Decoding error: unknown encoding: gb2312_charset\n",
      "Decoding error: unknown encoding: default\n",
      "Decoding error: unknown encoding: chinesebig5\n",
      "Decoding error: unknown encoding: default\n",
      "Decoding error: unknown encoding: default_charset\n",
      "Decoding error: unknown encoding: default\n",
      "Decoding error: unknown encoding: default\n",
      "Decoding error: unknown encoding: default\n",
      "Decoding error: unknown encoding: default_charset\n",
      "Decoding error: unknown encoding: default\n",
      "Decoding error: unknown encoding: default_charset\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "preprocessing_pipeline_tf = Pipeline([\n",
    "    (\"email_to_text\", EmailToTextTransformer()),\n",
    "    (\"tfidf\", TfidfVectorizer(\n",
    "        max_features=1000,\n",
    "        strip_accents=\"unicode\",\n",
    "        lowercase=True,\n",
    "        stop_words=\"english\",\n",
    "        ngram_range=(1, 2)\n",
    "    ))\n",
    "])\n",
    "\n",
    "X_train_transform_tf = preprocessing_pipeline_tf.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4d5d38ab-b38f-490d-bc11-76ec4763826e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9683908045977011)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "log_clf = LogisticRegression(max_iter=1000, random_state=42)\n",
    "score_vec = cross_val_score(log_clf, X_train_transform_vec, y_train, cv=3)\n",
    "score_vec.mean()\n",
    "\n",
    "# checking the vec edited dataset against LogReg, withoutout using GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d3aab424-af89-41d1-b050-7fc066af7d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9634646962233169)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_tf = cross_val_score(log_clf, X_train_transform_tf, y_train, cv=3)\n",
    "score_tf.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "65a596a2-b7f5-4f62-b70b-fbe8da16890f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.951559934318555)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# build a pipeline: scaling + SVM\n",
    "svm_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler(with_mean=False)), # important: with_mean=False because sparse matrix\n",
    "    (\"svm_clf\", SVC())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"svm_clf__C\": [0.1, 1, 10],\n",
    "    \"svm_clf__kernel\": [\"linear\", \"rbf\"],\n",
    "    \"svm_clf__gamma\": [\"scale\", \"auto\"]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(svm_pipeline, param_grid, cv=3, scoring=\"accuracy\", n_jobs=-1)\n",
    "grid_search.fit(X_train_transform_vec, y_train)\n",
    "\n",
    "svm_model = grid_search.best_estimator_\n",
    "\n",
    "score_svm = cross_val_score(svm_model, X_train_transform_vec, y_train, cv=3)\n",
    "score_svm.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "03f7b395-59a8-44d3-b2a6-0ff5482c122e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy (CV Mean): 0.9675697865353038\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression  # Import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Build a pipeline: scaling + Logistic Regression\n",
    "log_reg_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler(with_mean=False)),  # Important: with_mean=False because sparse matrix\n",
    "    (\"log_reg_clf\", LogisticRegression(solver='liblinear'))  # Logistic Regression classifier\n",
    "])\n",
    "\n",
    "# Define parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    \"log_reg_clf__C\": [0.1, 1, 10],  # Regularization parameter for Logistic Regression\n",
    "    \"log_reg_clf__penalty\": [\"l2\"],  # Regularization type (L2 is the default)\n",
    "    \"log_reg_clf__solver\": [\"liblinear\", \"saga\"]  # Solvers for optimization\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(log_reg_pipeline, param_grid, cv=3, scoring=\"accuracy\", n_jobs=-1)\n",
    "\n",
    "# Fit the model to the training data\n",
    "grid_search.fit(X_train_transform_vec, y_train)\n",
    "\n",
    "# Get the best model\n",
    "log_reg_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "score_log_reg = cross_val_score(log_reg_model, X_train_transform_vec, y_train, cv=3)\n",
    "print(\"Logistic Regression Accuracy (CV Mean):\", score_log_reg.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "960961fb-d247-4f01-9cc9-7800235a4d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding error: unknown encoding: default\n",
      "Decoding error: unknown encoding: default\n",
      "Decoding error: unknown encoding: default_charset\n",
      "Decoding error: unknown encoding: default_charset\n",
      "Decoding error: unknown encoding: default\n",
      "Decoding error: unknown encoding: default\n",
      "Decoding error: unknown encoding: default\n",
      "Decoding error: unknown encoding: default_charset\n",
      "Precision: 93.01%\n",
      "Recall: 95.83%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "X_test_transform_vec = preprocess_pipeline_vec.transform(X_test)\n",
    "\n",
    "y_pred_vec = log_reg_model.predict(X_test_transform_vec)\n",
    "\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_vec):.2%}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_vec):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f90e1787-2c96-4747-94af-2d331050c31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy (CV Mean): 0.972495894909688\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression  # Import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Build a pipeline: scaling + Logistic Regression\n",
    "log_reg_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler(with_mean=False)),  # Important: with_mean=False because sparse matrix\n",
    "    (\"log_reg_clf\", LogisticRegression(solver='liblinear', max_iter=1000))  # Logistic Regression classifier\n",
    "])\n",
    "\n",
    "# Define parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    \"log_reg_clf__C\": [0.1, 1, 10],  # Regularization parameter for Logistic Regression\n",
    "    \"log_reg_clf__penalty\": [\"l2\"],  # Regularization type (L2 is the default)\n",
    "    \"log_reg_clf__solver\": [\"liblinear\", \"saga\"]  # Solvers for optimization\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(log_reg_pipeline, param_grid, cv=3, scoring=\"accuracy\", n_jobs=-1)\n",
    "\n",
    "# Fit the model to the training data\n",
    "grid_search.fit(X_train_transform_tf, y_train)\n",
    "\n",
    "# Get the best model\n",
    "log_reg_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the model using cross-validation\n",
    "score_log_reg = cross_val_score(log_reg_model, X_train_transform_tf, y_train, cv=3)\n",
    "print(\"Logistic Regression Accuracy (CV Mean):\", score_log_reg.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a7f98b7f-7889-4ce2-a148-ce7e720d092b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding error: unknown encoding: default\n",
      "Decoding error: unknown encoding: default\n",
      "Decoding error: unknown encoding: default_charset\n",
      "Decoding error: unknown encoding: default_charset\n",
      "Decoding error: unknown encoding: default\n",
      "Decoding error: unknown encoding: default\n",
      "Decoding error: unknown encoding: default\n",
      "Decoding error: unknown encoding: default_charset\n",
      "Precision: 95.80%\n",
      "Recall: 95.08%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "X_test_transform_tf = preprocessing_pipeline_tf.transform(X_test)\n",
    "\n",
    "y_pred_vec = log_reg_model.predict(X_test_transform_tf)\n",
    "\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_vec):.2%}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_vec):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "750649db-a7d2-48c9-b9bf-3f00f08464f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "# Logistisc Regression Pipeline\n",
    "log_reg_pipeline2 = Pipeline([\n",
    "    (\"log_reg\", LogisticRegression(max_iter=1000, solver='saga', penalty='l2'))\n",
    "])\n",
    "\n",
    "# Random Forest Piipeline\n",
    "rf_pipeline = Pipeline([\n",
    "    (\"rf_clf\", RandomForestClassifier(n_estimators=100))\n",
    "])\n",
    "\n",
    "\n",
    "# Gradient Boosting Pipeline\n",
    "gb_pipeline = Pipeline([\n",
    "    (\"gb_clf\", GradientBoostingClassifier(n_estimators=100))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "49d2c762-6152-4220-bb1c-226fd982c7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"log_reg\", log_reg_pipeline2),\n",
    "        (\"rf\", rf_pipeline),\n",
    "        (\"gb\", gb_pipeline)\n",
    "    ],\n",
    "    voting=\"soft\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "73167008-0cba-48d1-83b1-17d82deb5ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9626436781609197)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_tf_ensm = cross_val_score(voting_clf, X_train_transform_tf, y_train, cv=3)\n",
    "score_tf_ensm.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "268ca335-a780-4e5e-badc-1b4db94dc82d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9704433497536945)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distributions = {\n",
    "    \"log_reg__log_reg__C\": [0.1, 1, 10],\n",
    "    \"rf__rf_clf__n_estimators\": [50, 100, 200],\n",
    "    \"gb__gb_clf__n_estimators\": [50, 100, 200]\n",
    "}\n",
    "\n",
    "rnd_search = RandomizedSearchCV(voting_clf, param_distributions, n_iter=10, cv=3, \n",
    "                                scoring=\"accuracy\", random_state=42)\n",
    "\n",
    "rnd_search.fit(X_train_transform_tf, y_train)\n",
    "\n",
    "best_voting_clf = rnd_search.best_estimator_\n",
    "\n",
    "score_rnd = cross_val_score(best_voting_clf, X_train_transform_tf, y_train, cv=3)\n",
    "score_rnd.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "60cea788-6bad-4a41-b212-c7bdea04509b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoding error: unknown encoding: default\n",
      "Decoding error: unknown encoding: default\n",
      "Decoding error: unknown encoding: default_charset\n",
      "Decoding error: unknown encoding: default_charset\n",
      "Decoding error: unknown encoding: default\n",
      "Decoding error: unknown encoding: default\n",
      "Decoding error: unknown encoding: default\n",
      "Decoding error: unknown encoding: default_charset\n",
      "Precision: 93.01%\n",
      "Recall: 95.83%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "X_test_transform_tf = preprocessing_pipeline_tf.transform(X_test)\n",
    "\n",
    "y_pred_vec = best_voting_clf.predict(X_test_transform_tf)\n",
    "\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_vec):.2%}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_vec):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "927b3b2c-98a3-418f-8574-cd821ebec81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy (CV Mean): 0.972495894909688\n",
      "Precision: 95.80%\n",
      "Recall: 95.08%\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "From all modelling, and work. The best scores came from when TfidVectorization and \n",
    "EmailToTextCounter were used to work on the ham nd spam data. Then the result training pipeline\n",
    "was used to train the data that was in X_train. After that LogisticRegression in combination with\n",
    "GridSearchCV was used to remodel and get the best model features that worked with the LogRess\n",
    "model. This gave a cross val score of 0.9724, and Precision: 95.80% & Recall: 95.08%. Other \n",
    "models, even an ensemble of RF and LogRess was used. But this model (log_reg_model) was the best\n",
    "\"\"\"\n",
    "\n",
    "score_log_reg = cross_val_score(log_reg_model, X_train_transform_tf, y_train, cv=3)\n",
    "print(\"Logistic Regression Accuracy (CV Mean):\", score_log_reg.mean())\n",
    "\n",
    "y_pred_vec = log_reg_model.predict(X_test_transform_tf)\n",
    "\n",
    "print(f\"Precision: {precision_score(y_test, y_pred_vec):.2%}\")\n",
    "print(f\"Recall: {recall_score(y_test, y_pred_vec):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bc8e95-b7ed-4fae-a85c-87bf6b531b48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
